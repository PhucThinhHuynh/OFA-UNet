{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":13920495,"sourceType":"datasetVersion","datasetId":8870348}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"papermill":{"default_parameters":{},"duration":12223.059804,"end_time":"2025-11-04T06:12:39.800522","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-11-04T02:48:56.740718","version":"2.6.0"},"widgets":{"application/vnd.jupyter.widget-state+json":{"state":{"04545f8eec924ce0886fde009ef6abcc":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0caf3f4300344b5094e82fd67485f678":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"12162e23fa14472e9fda90cd0c9d9ac9":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8988809520834b9bb2e20d24521003cd","IPY_MODEL_79022f894e1943dfb18db85eed7c7fdc","IPY_MODEL_e5908849df8c419b9795b3c43c27b691"],"layout":"IPY_MODEL_0caf3f4300344b5094e82fd67485f678","tabbable":null,"tooltip":null}},"2656125313f247c0a1ab0c012b4382fb":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"319ee756c26b40b88a35f1e9d2611fba":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_c68aadc184a54d6c818dafe56362eb1e","placeholder":"​","style":"IPY_MODEL_b9b62923f4594ea3bf7d26aad5f91b10","tabbable":null,"tooltip":null,"value":"config.json: 100%"}},"35cfcc0c1c0a4d058cb389b7bc4792cc":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_563ae69368b04ac4b9abdcc919165985","placeholder":"​","style":"IPY_MODEL_857756be2c0d4b2ba0c8b5203fe755ce","tabbable":null,"tooltip":null,"value":" 6.88k/6.88k [00:00&lt;00:00, 804kB/s]"}},"41ed13ca21c94aee8cb8f600470f4bc7":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_319ee756c26b40b88a35f1e9d2611fba","IPY_MODEL_47066d64a75a424590c39b821a5b7932","IPY_MODEL_35cfcc0c1c0a4d058cb389b7bc4792cc"],"layout":"IPY_MODEL_72f0e34300d24eb4bcc4a2107d30ff87","tabbable":null,"tooltip":null}},"47066d64a75a424590c39b821a5b7932":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_f78f5c4c7d454143b36d671f11b9fc58","max":6884,"min":0,"orientation":"horizontal","style":"IPY_MODEL_04545f8eec924ce0886fde009ef6abcc","tabbable":null,"tooltip":null,"value":6884}},"563ae69368b04ac4b9abdcc919165985":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"72f0e34300d24eb4bcc4a2107d30ff87":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"79022f894e1943dfb18db85eed7c7fdc":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_b2548784871240b6b0e9c1770370ab32","max":15036944,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fa102e1df1a246849b52e94596274a22","tabbable":null,"tooltip":null,"value":15036944}},"857756be2c0d4b2ba0c8b5203fe755ce":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"8988809520834b9bb2e20d24521003cd":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_2656125313f247c0a1ab0c012b4382fb","placeholder":"​","style":"IPY_MODEL_925da347826443508f25fe444f288ab0","tabbable":null,"tooltip":null,"value":"model.safetensors: 100%"}},"925da347826443508f25fe444f288ab0":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"b2548784871240b6b0e9c1770370ab32":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b9b62923f4594ea3bf7d26aad5f91b10":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"bf49131c30154a35b41e1a79a011f581":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"c68aadc184a54d6c818dafe56362eb1e":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e47bf67d5f414137aa34c5e297245505":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e5908849df8c419b9795b3c43c27b691":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_e47bf67d5f414137aa34c5e297245505","placeholder":"​","style":"IPY_MODEL_bf49131c30154a35b41e1a79a011f581","tabbable":null,"tooltip":null,"value":" 15.0M/15.0M [00:00&lt;00:00, 68.8MB/s]"}},"f78f5c4c7d454143b36d671f11b9fc58":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fa102e1df1a246849b52e94596274a22":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}}},"version_major":2,"version_minor":0}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install segmentation-models-pytorch","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":0.011831,"end_time":"2025-11-04T02:49:00.716407","exception":false,"start_time":"2025-11-04T02:49:00.704576","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T14:39:33.205645Z","iopub.execute_input":"2026-02-02T14:39:33.205805Z","iopub.status.idle":"2026-02-02T14:40:57.340441Z","shell.execute_reply.started":"2026-02-02T14:39:33.205788Z","shell.execute_reply":"2026-02-02T14:40:57.339641Z"}},"outputs":[{"name":"stdout","text":"Collecting segmentation-models-pytorch\n  Downloading segmentation_models_pytorch-0.5.0-py3-none-any.whl.metadata (17 kB)\nRequirement already satisfied: huggingface-hub>=0.24 in /usr/local/lib/python3.11/dist-packages (from segmentation-models-pytorch) (0.36.0)\nRequirement already satisfied: numpy>=1.19.3 in /usr/local/lib/python3.11/dist-packages (from segmentation-models-pytorch) (1.26.4)\nRequirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from segmentation-models-pytorch) (11.3.0)\nRequirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from segmentation-models-pytorch) (0.5.3)\nRequirement already satisfied: timm>=0.9 in /usr/local/lib/python3.11/dist-packages (from segmentation-models-pytorch) (1.0.19)\nRequirement already satisfied: torch>=1.8 in /usr/local/lib/python3.11/dist-packages (from segmentation-models-pytorch) (2.6.0+cu124)\nRequirement already satisfied: torchvision>=0.9 in /usr/local/lib/python3.11/dist-packages (from segmentation-models-pytorch) (0.21.0+cu124)\nRequirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from segmentation-models-pytorch) (4.67.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (3.20.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (2025.10.0)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (6.0.3)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (2.32.5)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (4.15.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (1.2.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.3->segmentation-models-pytorch) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.3->segmentation-models-pytorch) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.3->segmentation-models-pytorch) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.3->segmentation-models-pytorch) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.3->segmentation-models-pytorch) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.3->segmentation-models-pytorch) (2.4.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation-models-pytorch) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation-models-pytorch) (3.1.6)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8->segmentation-models-pytorch)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8->segmentation-models-pytorch)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8->segmentation-models-pytorch)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8->segmentation-models-pytorch)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8->segmentation-models-pytorch)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8->segmentation-models-pytorch)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8->segmentation-models-pytorch)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8->segmentation-models-pytorch)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8->segmentation-models-pytorch)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation-models-pytorch) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation-models-pytorch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation-models-pytorch) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8->segmentation-models-pytorch)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation-models-pytorch) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation-models-pytorch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8->segmentation-models-pytorch) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8->segmentation-models-pytorch) (3.0.3)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.19.3->segmentation-models-pytorch) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.19.3->segmentation-models-pytorch) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.19.3->segmentation-models-pytorch) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.19.3->segmentation-models-pytorch) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.19.3->segmentation-models-pytorch) (2024.2.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.24->segmentation-models-pytorch) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.24->segmentation-models-pytorch) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.24->segmentation-models-pytorch) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.24->segmentation-models-pytorch) (2025.10.5)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.19.3->segmentation-models-pytorch) (2024.2.0)\nDownloading segmentation_models_pytorch-0.5.0-py3-none-any.whl (154 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.8/154.8 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m106.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m73.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m48.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m72.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0mm\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, segmentation-models-pytorch\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 segmentation-models-pytorch-0.5.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# from mamba_ssm.ops.selective_scan_interface import selective_scan_fn, selective_scan_ref\n\nimport os\nimport glob\nimport numpy as np\nimport cv2\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nfrom torchmetrics import Accuracy, JaccardIndex\nfrom tqdm import tqdm\n\n\n# Cấu hình OpenCV để tránh xung đột\ncv2.setNumThreads(0)\ncv2.ocl.setUseOpenCL(False)\n\n# Định nghĩa các hằng số\nCLASSES = [\"Noise\", \"LTE\", \"NR\", \"Radar\"]\nCOLORMAP = [[0, 0, 0], [80, 80, 80], [160, 160, 160], [255, 255, 255]]","metadata":{"papermill":{"duration":16.937625,"end_time":"2025-11-04T02:49:17.658890","exception":false,"start_time":"2025-11-04T02:49:00.721265","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T14:40:57.342147Z","iopub.execute_input":"2026-02-02T14:40:57.342383Z","iopub.status.idle":"2026-02-02T14:41:14.260226Z","shell.execute_reply.started":"2026-02-02T14:40:57.342357Z","shell.execute_reply":"2026-02-02T14:41:14.259387Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"# data","metadata":{"papermill":{"duration":0.004631,"end_time":"2025-11-04T02:49:17.668777","exception":false,"start_time":"2025-11-04T02:49:17.664146","status":"completed"},"tags":[]}},{"cell_type":"code","source":"train_transform = transforms.Compose([\n    transforms.ToPILImage(),\n    transforms.ToTensor()\n])\n\n\n\n# Định nghĩa Dataset\nclass SearchDataset(Dataset):\n    def __init__(self, root=\"/kaggle/input/IRecSpecUNet\", image_set=\"train\", download=True, transform=None):\n        self.images = sorted(glob.glob(os.path.join(root, image_set, 'input', '*.png')))\n        self.masks = sorted(glob.glob(os.path.join(root, image_set, 'label', '*.png')))\n        self.transform = transform\n        self.classes = len(COLORMAP)  # Số lớp (4 trong trường hợp này)\n\n    def __len__(self):\n        return len(self.images)\n\n    @staticmethod\n    def _convert_to_segmentation_mask(mask):\n        # Chuyển mask RGB thành nhãn lớp đơn kênh\n        height, width = mask.shape[:2]\n        segmentation_mask = np.zeros((height, width), dtype=np.uint8)  # Chỉ cần 1 kênh cho nhãn lớp\n        for label_index, label_color in enumerate(COLORMAP):\n            segmentation_mask[np.all(mask == label_color, axis=-1)] = label_index\n        return segmentation_mask\n\n    def __getitem__(self, index):\n        image = cv2.imread(self.images[index])\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        mask = cv2.imread(self.masks[index])\n        mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)\n        mask = self._convert_to_segmentation_mask(mask)  # Giờ mask là 2D với nhãn lớp\n\n        if self.transform is not None:\n            image = self.transform(image) \n            mask = torch.from_numpy(mask).long()  # Chuyển mask thành tensor long\n\n        return image, mask\n\n# Tạo dataset và dataloader\ntrain_dataset = SearchDataset(image_set=\"train\", download=True, transform=train_transform)\ntest_dataset = SearchDataset(image_set=\"val\", download=False, transform=train_transform)\n\n# Cấu hình dataloader\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nbatch_size = 32\nn_workers = os.cpu_count()\n\ntrainloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=n_workers)\ntestloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=n_workers)","metadata":{"papermill":{"duration":1.206976,"end_time":"2025-11-04T02:49:18.880345","exception":false,"start_time":"2025-11-04T02:49:17.673369","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T14:41:14.261145Z","iopub.execute_input":"2026-02-02T14:41:14.262142Z","iopub.status.idle":"2026-02-02T14:41:26.706188Z","shell.execute_reply.started":"2026-02-02T14:41:14.262096Z","shell.execute_reply":"2026-02-02T14:41:26.705572Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Lấy ảnh đầu tiên từ tập test\ntest_dataset = SearchDataset(image_set=\"val\", download=False, transform=None)  # Không áp dụng transform để lấy ảnh gốc\nimage, mask = test_dataset[0]\n\n# Chuyển đổi tensor hoặc numpy array về định dạng phù hợp để hiển thị\nimage = image.numpy().transpose(1, 2, 0) if isinstance(image, torch.Tensor) else image  # Nếu ảnh là tensor, chuyển về numpy\nmask = mask.numpy() if isinstance(mask, torch.Tensor) else mask  # Chuyển mask về numpy nếu cần\n\n# Tạo colormap cho mask dựa trên COLORMAP\nfrom matplotlib.colors import ListedColormap\ncmap = ListedColormap(np.array(COLORMAP) / 255.0)  # Chuẩn hóa COLORMAP về [0, 1]\n\n# Hiển thị ảnh và mask\nplt.figure(figsize=(10, 5))\n\n# Hiển thị ảnh gốc\nplt.subplot(1, 2, 1)\nplt.title(\"Input Image\")\nplt.imshow(image)\nplt.axis('off')\n\n# Hiển thị mask\nplt.subplot(1, 2, 2)\nplt.title(\"Mask\")\nplt.imshow(mask, cmap=cmap, vmin=0, vmax=len(COLORMAP)-1)\nplt.axis('off')\n\nplt.show()","metadata":{"papermill":{"duration":0.352039,"end_time":"2025-11-04T02:49:19.237332","exception":false,"start_time":"2025-11-04T02:49:18.885293","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T14:41:26.706906Z","iopub.execute_input":"2026-02-02T14:41:26.707160Z","iopub.status.idle":"2026-02-02T14:41:27.383809Z","shell.execute_reply.started":"2026-02-02T14:41:26.707132Z","shell.execute_reply":"2026-02-02T14:41:27.383174Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x500 with 2 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":4},{"cell_type":"markdown","source":"# model","metadata":{"papermill":{"duration":0.0055,"end_time":"2025-11-04T02:49:19.249031","exception":false,"start_time":"2025-11-04T02:49:19.243531","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass OFAGConv(nn.Module):  # 3x1\n    def __init__(self, c1, c2, k=1, s=1, p=None, g=1, d=1, ofag=8, use_relu=True):\n        super().__init__()\n        self.g = ofag\n        self.c_ = c2 // self.g\n        self.use_relu = use_relu\n\n        # --- Xử lý kernel size và stride ---\n        self.k = k if isinstance(k, tuple) else (k, k)\n        kh, kw = self.k\n        self.s = s if isinstance(s, tuple) else (s, s)\n\n        # --- Tính padding nếu không được cung cấp ---\n        if p is None:\n            ph = (kh - 1) // 2\n            pw = (kw - 1) // 2\n            p = (ph, pw)\n        self.p = p\n\n        # --- Convolution cơ bản ---\n        self.conv = nn.Conv2d(\n            c1 // self.g, self.c_,\n            kernel_size=self.k, stride=self.s,\n            padding=self.p, groups=g, dilation=d, bias=False\n        )\n\n        # --- BatchNorm + ReLU ---\n        if self.use_relu:\n            self.bn_silu = nn.Sequential(\n                nn.BatchNorm2d(c2),\n                nn.ReLU(inplace=True)\n            )\n        else:\n            self.bn_silu = nn.BatchNorm2d(c2)\n\n        # --- Tham số scale riêng cho từng group (kể cả group 0) ---\n        self.trainable_scale_cc = nn.ParameterList([\n            nn.Parameter(torch.ones(c1 // self.g, 1, 1)) for _ in range(self.g)\n        ])\n        self.trainable_scale_sc = nn.ParameterList([\n            nn.Parameter(torch.ones(1, kh, kw)) for _ in range(self.g)\n        ])\n\n        # --- Kernel lưu lại (nếu cần dùng sau này) ---\n        self.saved_kernel = None\n\n    def forward(self, x):\n        chunks = torch.chunk(x, self.g, dim=1)\n        processed_chunks = []\n\n        for i, c in enumerate(chunks):\n            weight = self.conv.weight\n\n            # scale cho mọi group, kể cả group 0\n            scale_cc = self.trainable_scale_cc[i]\n            scale_sc = self.trainable_scale_sc[i]\n            weight = weight * scale_cc * scale_sc\n\n            # dùng cùng 1 self.conv cho mọi chunk\n            out = F.conv2d(c, weight, padding=self.p, stride=self.s)\n            # out = self.bn_silu(out)\n            processed_chunks.append(out)\n\n        return self.bn_silu(torch.cat(processed_chunks, dim=1))\n\nclass OFABasicBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, stride=1, groups=1, downsample=None):\n        super().__init__()\n        self.ofag=groups\n        self.ofaconv1 = OFAGConv(c1=in_channels, c2=out_channels, k=(3,3), s=stride, ofag=8, use_relu=True)\n        self.ofaconv2 = OFAGConv(c1=out_channels, c2=out_channels, k=(3,3), s=1, ofag=8, use_relu=False)\n        self.downsample = downsample\n        self.relu = nn.ReLU(inplace=True)\n        # self.ca = SA(out_channels)\n\n    def forward(self, x):\n        identity = x\n        out = self.ofaconv1(x)\n        out = self.ofaconv2(out)\n\n        if self.downsample is not None:\n            identity = self.downsample(x)\n\n        out += identity\n        out = self.relu(out)\n        return out\n        # return self.ca(out)\n# ======== BasicBlock ========\nclass BasicBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, stride=1, groups=1, downsample=None):\n        super().__init__()\n        self.groups = groups\n        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False, groups=groups)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False, groups=groups)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n        self.downsample = downsample\n        # self.ca = SA(out_channels)\n        \n\n    def forward(self, x):\n        identity = x\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n        out = self.conv2(out)\n        out = self.bn2(out)\n\n        if self.downsample is not None:\n            identity = self.downsample(x)\n\n        out += identity\n        out = self.relu(out)\n        return out\n        # return self.ca(out)\n\n\n# ======== ResNetEncoder ========\nclass ResNetEncoder(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.gshallow = 1\n        self.gdeep = 1\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU(inplace=True)\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n\n        self.layer1 = self._make_layer(64, 64, blocks=2, stride=1, groups=self.gshallow)\n        self.layer2 = self._make_ofa_layer(64, 128, blocks=2, stride=2, groups=self.gshallow)\n        # self.layer3 = self._make_layer(128, 256, blocks=2, stride=2, groups=self.gdeep)\n        # self.layer4 = self._make_layer(256, 512, blocks=2, stride=2, groups=self.gdeep)\n        self.layer3 = self._make_ofa_layer(128, 256, blocks=2, stride=2, groups=self.gdeep)\n        self.layer4 = self._make_ofa_layer(256, 512, blocks=2, stride=2, groups=self.gdeep)\n\n    def _make_layer(self, in_channels, out_channels, blocks, stride, groups):\n        downsample = None\n        if stride != 1 or in_channels != out_channels: #res identity\n            downsample = nn.Sequential(\n                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(out_channels)\n            )\n        layers = [BasicBlock(in_channels, out_channels, stride, groups, downsample)]\n        for _ in range(1, blocks):\n            layers.append(BasicBlock(out_channels, out_channels))\n        return nn.Sequential(*layers)\n        \n    def _make_ofa_layer(self, in_channels, out_channels, blocks, stride, groups):\n        downsample = None\n        if stride != 1 or in_channels != out_channels: #res identity\n            downsample = nn.Sequential(\n                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(out_channels)\n            )\n        layers = [OFABasicBlock(in_channels, out_channels, stride, groups, downsample)]\n        for _ in range(1, blocks):\n            layers.append(OFABasicBlock(out_channels, out_channels))\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        x0 = self.relu(self.bn1(self.conv1(x)))  # [B, 64, H/2, W/2]\n        x1 = self.maxpool(x0)                   # [B, 64, H/4, W/4]\n        x2 = self.layer1(x1)                    # [B, 64, H/4, W/4]\n        x3 = self.layer2(x2)                    # [B, 128, H/8, W/8]\n        x4 = self.layer3(x3)                    # [B, 256, H/16, W/16]\n        x5 = self.layer4(x4)                    # [B, 512, H/32, W/32]\n        return [x0, x2, x3, x4, x5]\n\n# ======== DecoderBlock ========\nclass Conv2dReLU(nn.Sequential):\n    def __init__(self, in_channels, out_channels, groups):\n        super().__init__(\n            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, bias=False, groups= groups),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True)\n        )\n\nclass Attention(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.attention = nn.Identity()\n    def forward(self, x):\n        return self.attention(x)\n\n\nclass GlobalBranch(nn.Module):\n    def __init__(self, e_lambda=1e-4):\n        super(GlobalBranch, self).__init__()\n        self.activaton = nn.Sigmoid()\n        self.e_lambda = e_lambda\n        # self.conv_1x1 = nn.Conv2d(2, 1, kernel_size=1, bias=False)\n        # self.bn = nn.BatchNorm2d(1)\n    def forward(self, x):\n        # 1. Lấy kích thước (b, c, h, w)\n        # x=self.bn(self.conv_1x1(x))\n        b, c, h, w = x.size()\n        # 2. Tính số lượng phần tử không gian (n = H * W - 1)\n        # Trừ 1 để dùng cho công thức phương sai mẫu (Unbiased Sample Variance)\n        n = w * h - 1\n        # 3. Tính (x - mu)^2\n        # keepdim=True giúp giữ nguyên chiều (b, c, 1, 1) để broadcast chính xác khi trừ\n        x_minus_mu_square = (x - x.mean(dim=[2, 3], keepdim=True)).pow(2)\n        # 4. Tính phương sai của kênh (Channel Variance)\n        # v = sum((x - mu)^2) / n\n        y = x_minus_mu_square / (4 * (x_minus_mu_square.sum(dim=[2, 3], keepdim=True) / n + self.e_lambda)) + 0.5\n        # 5. Áp dụng Sigmoid và nhân với input gốc\n        return x * self.activaton(y) \n\nclass DCA(nn.Module):\n    \"\"\"Spatial-attention module.\"\"\"\n    def __init__(self, channel=4):\n        super().__init__()\n        # assert len(kernel_sizes) >= 2, \"cần ít nhất 2 kernel sizes\"\n        # branch từ (avg,max) concat -> conv3x3, conv7x7 (2->1)\n        self.conv_large = GlobalBranch(1e-4)\n        # self.bn = nn.BatchNorm2d(1)\n        self.conv_small = nn.Conv2d(channel, channel, kernel_size=3,\n                                    padding=(3//2), bias=False)\n\n\n    def forward(self, x):\n        \"\"\"\n        x: [B, C, H, W]\n        returns: [B, C, H, W] (recalibrated features)\n        \"\"\"\n        out = self.conv_large(x) + self.conv_small(x)\n        return x\n\nclass HAF(nn.Module):\n    def __init__(self, in_channels=128, num_classes=4):\n        super().__init__()\n        # Sửa lỗi: Giả định class SA đã định nghĩa, cần gọi self.sa thay vì self.SA (nếu tên biến là sa)\n        self.sa = DCA(num_classes) \n        # self.drop = nn.Dropout(0.1)\n        self.conv_out = nn.Conv2d(in_channels, num_classes, kernel_size=1, dilation=1, stride=1, padding=0, bias=False)\n\n    def forward(self, x, h, w):\n        # Sửa lỗi: gọi self.sa (instance) chứ không phải self.SA (class)\n        x = self.conv_out(x)\n        # x = self.drop(x)\n        # Upsample về kích thước target (h, w) để tính loss hoặc cộng gộp\n        x = F.interpolate(x, size=(h, w), mode='bilinear', align_corners=False)\n        x = self.sa(x) \n        return x\n\nclass UnetDecoderBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, groups, num_classes=4, aux=False):\n        super().__init__()\n        self.aux=aux\n        self.conv1 = Conv2dReLU(in_channels, out_channels, groups)\n        self.attention1 = Attention()\n        self.conv2 = Conv2dReLU(out_channels, out_channels, groups)\n        self.attention2 = Attention()\n        # Khởi tạo layer LSM một lần duy nhất ở đây\n        self.haf = HAF(out_channels, num_classes)\n        \n\n    def forward(self, x, skip=None, target_size=(256, 256)):\n        x = F.interpolate(x, scale_factor=2, mode=\"nearest\")\n        if skip is not None:\n            x = torch.cat([x, skip], dim=1)\n        x = self.conv1(x)\n        x = self.attention1(x)\n        x = self.conv2(x)\n        x = self.attention2(x)\n        \n        # LOGIC QUAN TRỌNG: Chỉ chạy nhánh aux khi đang training\n        aux_output = None\n        if self.training and self.aux:\n            # Dùng self.haf đã init, truyền vào kích thước ảnh mong muốn (ví dụ 256x256)\n            aux_output = self.haf(x, target_size[0], target_size[1])\n            \n        return x, aux_output\n\nclass UnetOFADecoderBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, groups, num_classes=4, aux=False):\n        super().__init__()\n        self.aux=aux\n        self.conv1 = OFAGConv(c1=in_channels, c2=out_channels, k=(3,3), s=1, ofag=8, use_relu=False)\n        self.attention1 = Attention()\n        self.conv2 = OFAGConv(c1=out_channels, c2=out_channels, k=(3,3), s=1, ofag=8, use_relu=False)\n        self.attention2 = Attention()\n        # Khởi tạo LSM\n        self.haf = HAF(out_channels, num_classes)\n\n    def forward(self, x, skip=None, target_size=(256, 256)):\n        x = F.interpolate(x, scale_factor=2, mode=\"nearest\")\n        if skip is not None:\n            x = torch.cat([x, skip], dim=1)\n        x = self.conv1(x)\n        x = self.attention1(x)\n        x = self.conv2(x)\n        x = self.attention2(x)\n        \n        # LOGIC QUAN TRỌNG: Chỉ chạy nhánh aux khi đang training\n        aux_output = None\n        if self.training and self.aux:\n            aux_output = self.haf(x, target_size[0], target_size[1])\n            \n        return x, aux_output\n\n# ======== UnetDecoder ========\nclass UnetDecoder(nn.Module):\n    # Bỏ tham số 'training' ở init, nn.Module tự quản lý\n    def __init__(self, num_classes=4): \n        super().__init__()\n        self.center = nn.Identity()\n        self.gshallow = 1\n        self.gdeep = 1\n        self.num_class = num_classes\n        # self.gct = GCT(num_classes*3)\n        \n        # Truyền num_classes vào các block để LSM biết output bao nhiêu lớp\n        self.blocks = nn.ModuleList([\n            UnetOFADecoderBlock(512 + 256, 256, self.gdeep, num_classes, aux=True),\n            UnetOFADecoderBlock(256 + 128, 128, self.gdeep, num_classes, aux=True),\n            UnetDecoderBlock(128 + 64, 64, self.gshallow, num_classes, aux=True),\n            UnetDecoderBlock(64 + 64, 32, self.gshallow, num_classes, aux=False),\n            UnetDecoderBlock(32, 16, self.gshallow, num_classes, aux=False),\n        ])\n\n    def forward(self, features):\n        x5, x4, x3, x2, x1 = features[::-1]  # reversed for decoder\n        x = self.center(x5)\n        skips = [x4, x3, x2, x1, None]\n        \n        haf_outputs = [] # Sửa lỗi chính tả lsm_ouput -> haf_outputs\n        \n        # Giả sử kích thước ảnh gốc là 256x256, hoặc bạn có thể truyền vào forward\n        target_h, target_w = 256, 256 \n        \n        for block, skip in zip(self.blocks, skips):\n            # Truyền target_size vào block để LSM interpolate đúng kích thước\n            x, aux = block(x, skip, target_size=(target_h, target_w))\n            \n            # Chỉ thu thập aux output nếu nó tồn tại (tức là đang training)\n            if aux is not None:\n                haf_outputs.append(aux)\n            \n        # Return kết quả\n       # --- PHẦN SỬA ĐỔI ---\n        if self.training and len(haf_outputs) > 0:\n\n            haf_stack = torch.stack(haf_outputs, dim=0)   # [N_aux, B, C, H, W]\n            haf_final = torch.sum(haf_stack, dim=0)       # [B, C, H, W]\n\n            return x, haf_final\n            \n        else:\n            return x, None\n\n# ======== SegmentationHead ========\nclass SegmentationHead(nn.Sequential):\n    def __init__(self, in_channels, out_channels):\n        super().__init__(\n            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n            nn.Identity(),\n            nn.Identity()  \n        )\n\nclass OFAUnet(nn.Module):\n    def __init__(self, num_classes):\n        super().__init__()\n        self.encoder = ResNetEncoder() # Giả định đã có class này\n        # Không truyền 'training' vào init của Decoder nữa\n        self.decoder = UnetDecoder(num_classes=num_classes)\n        self.segmentation_head = SegmentationHead(16, num_classes)\n\n    def forward(self, x):\n        # Lấy kích thước ảnh đầu vào để truyền xuống decoder (nếu muốn dynamic size)\n        input_size = x.shape[-2:] \n        \n        features = self.encoder(x)\n        \n        # Decoder trả về x và aux_output (có thể là None)\n        x_dec, aux_output = self.decoder(features)\n        \n        # Head chính\n        x_out = self.segmentation_head(x_dec)\n        \n        # Logic Return cuối cùng\n        if self.training:\n            # Khi train: Trả về cả output chính và aux output\n            return x_out, aux_output\n        else:\n            # Khi inference/eval: Chỉ trả về output chính\n            return x_out\n\nmodel = OFAUnet(4).to(device)\nmodel = nn.DataParallel(model)\n\n# print(model)\ntotal_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\nprint(f\"Tổng số tham số có thể huấn luyện: {total_params:,}\")\nprint(model)\n\"\"\"\n--OFA-UNet\n\"\"\"","metadata":{"papermill":{"duration":0.253038,"end_time":"2025-11-04T02:49:19.507600","exception":false,"start_time":"2025-11-04T02:49:19.254562","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T14:41:27.384668Z","iopub.execute_input":"2026-02-02T14:41:27.384907Z","iopub.status.idle":"2026-02-02T14:41:27.648072Z","shell.execute_reply.started":"2026-02-02T14:41:27.384889Z","shell.execute_reply":"2026-02-02T14:41:27.647473Z"}},"outputs":[{"name":"stdout","text":"Tổng số tham số có thể huấn luyện: 765,460\nDataParallel(\n  (module): OFAUnet(\n    (encoder): ResNetEncoder(\n      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n      (layer1): Sequential(\n        (0): BasicBlock(\n          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU(inplace=True)\n          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (1): BasicBlock(\n          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU(inplace=True)\n          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (layer2): Sequential(\n        (0): OFABasicBlock(\n          (ofaconv1): OFAGConv(\n            (conv): Conv2d(8, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n            (bn_silu): Sequential(\n              (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (1): ReLU(inplace=True)\n            )\n            (trainable_scale_cc): ParameterList(\n                (0): Parameter containing: [torch.float32 of size 8x1x1 (cuda:0)]\n                (1): Parameter containing: [torch.float32 of size 8x1x1 (cuda:0)]\n                (2): Parameter containing: [torch.float32 of size 8x1x1 (cuda:0)]\n                (3): Parameter containing: [torch.float32 of size 8x1x1 (cuda:0)]\n                (4): Parameter containing: [torch.float32 of size 8x1x1 (cuda:0)]\n                (5): Parameter containing: [torch.float32 of size 8x1x1 (cuda:0)]\n                (6): Parameter containing: [torch.float32 of size 8x1x1 (cuda:0)]\n                (7): Parameter containing: [torch.float32 of size 8x1x1 (cuda:0)]\n            )\n            (trainable_scale_sc): ParameterList(\n                (0): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (1): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (2): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (3): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (4): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (5): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (6): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (7): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n            )\n          )\n          (ofaconv2): OFAGConv(\n            (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn_silu): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (trainable_scale_cc): ParameterList(\n                (0): Parameter containing: [torch.float32 of size 16x1x1 (cuda:0)]\n                (1): Parameter containing: [torch.float32 of size 16x1x1 (cuda:0)]\n                (2): Parameter containing: [torch.float32 of size 16x1x1 (cuda:0)]\n                (3): Parameter containing: [torch.float32 of size 16x1x1 (cuda:0)]\n                (4): Parameter containing: [torch.float32 of size 16x1x1 (cuda:0)]\n                (5): Parameter containing: [torch.float32 of size 16x1x1 (cuda:0)]\n                (6): Parameter containing: [torch.float32 of size 16x1x1 (cuda:0)]\n                (7): Parameter containing: [torch.float32 of size 16x1x1 (cuda:0)]\n            )\n            (trainable_scale_sc): ParameterList(\n                (0): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (1): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (2): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (3): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (4): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (5): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (6): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (7): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n            )\n          )\n          (downsample): Sequential(\n            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n          (relu): ReLU(inplace=True)\n        )\n        (1): OFABasicBlock(\n          (ofaconv1): OFAGConv(\n            (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn_silu): Sequential(\n              (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (1): ReLU(inplace=True)\n            )\n            (trainable_scale_cc): ParameterList(\n                (0): Parameter containing: [torch.float32 of size 16x1x1 (cuda:0)]\n                (1): Parameter containing: [torch.float32 of size 16x1x1 (cuda:0)]\n                (2): Parameter containing: [torch.float32 of size 16x1x1 (cuda:0)]\n                (3): Parameter containing: [torch.float32 of size 16x1x1 (cuda:0)]\n                (4): Parameter containing: [torch.float32 of size 16x1x1 (cuda:0)]\n                (5): Parameter containing: [torch.float32 of size 16x1x1 (cuda:0)]\n                (6): Parameter containing: [torch.float32 of size 16x1x1 (cuda:0)]\n                (7): Parameter containing: [torch.float32 of size 16x1x1 (cuda:0)]\n            )\n            (trainable_scale_sc): ParameterList(\n                (0): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (1): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (2): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (3): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (4): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (5): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (6): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (7): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n            )\n          )\n          (ofaconv2): OFAGConv(\n            (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn_silu): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (trainable_scale_cc): ParameterList(\n                (0): Parameter containing: [torch.float32 of size 16x1x1 (cuda:0)]\n                (1): Parameter containing: [torch.float32 of size 16x1x1 (cuda:0)]\n                (2): Parameter containing: [torch.float32 of size 16x1x1 (cuda:0)]\n                (3): Parameter containing: [torch.float32 of size 16x1x1 (cuda:0)]\n                (4): Parameter containing: [torch.float32 of size 16x1x1 (cuda:0)]\n                (5): Parameter containing: [torch.float32 of size 16x1x1 (cuda:0)]\n                (6): Parameter containing: [torch.float32 of size 16x1x1 (cuda:0)]\n                (7): Parameter containing: [torch.float32 of size 16x1x1 (cuda:0)]\n            )\n            (trainable_scale_sc): ParameterList(\n                (0): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (1): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (2): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (3): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (4): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (5): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (6): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (7): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n            )\n          )\n          (relu): ReLU(inplace=True)\n        )\n      )\n      (layer3): Sequential(\n        (0): OFABasicBlock(\n          (ofaconv1): OFAGConv(\n            (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n            (bn_silu): Sequential(\n              (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (1): ReLU(inplace=True)\n            )\n            (trainable_scale_cc): ParameterList(\n                (0): Parameter containing: [torch.float32 of size 16x1x1 (cuda:0)]\n                (1): Parameter containing: [torch.float32 of size 16x1x1 (cuda:0)]\n                (2): Parameter containing: [torch.float32 of size 16x1x1 (cuda:0)]\n                (3): Parameter containing: [torch.float32 of size 16x1x1 (cuda:0)]\n                (4): Parameter containing: [torch.float32 of size 16x1x1 (cuda:0)]\n                (5): Parameter containing: [torch.float32 of size 16x1x1 (cuda:0)]\n                (6): Parameter containing: [torch.float32 of size 16x1x1 (cuda:0)]\n                (7): Parameter containing: [torch.float32 of size 16x1x1 (cuda:0)]\n            )\n            (trainable_scale_sc): ParameterList(\n                (0): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (1): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (2): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (3): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (4): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (5): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (6): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (7): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n            )\n          )\n          (ofaconv2): OFAGConv(\n            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn_silu): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (trainable_scale_cc): ParameterList(\n                (0): Parameter containing: [torch.float32 of size 32x1x1 (cuda:0)]\n                (1): Parameter containing: [torch.float32 of size 32x1x1 (cuda:0)]\n                (2): Parameter containing: [torch.float32 of size 32x1x1 (cuda:0)]\n                (3): Parameter containing: [torch.float32 of size 32x1x1 (cuda:0)]\n                (4): Parameter containing: [torch.float32 of size 32x1x1 (cuda:0)]\n                (5): Parameter containing: [torch.float32 of size 32x1x1 (cuda:0)]\n                (6): Parameter containing: [torch.float32 of size 32x1x1 (cuda:0)]\n                (7): Parameter containing: [torch.float32 of size 32x1x1 (cuda:0)]\n            )\n            (trainable_scale_sc): ParameterList(\n                (0): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (1): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (2): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (3): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (4): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (5): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (6): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (7): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n            )\n          )\n          (downsample): Sequential(\n            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n          (relu): ReLU(inplace=True)\n        )\n        (1): OFABasicBlock(\n          (ofaconv1): OFAGConv(\n            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn_silu): Sequential(\n              (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (1): ReLU(inplace=True)\n            )\n            (trainable_scale_cc): ParameterList(\n                (0): Parameter containing: [torch.float32 of size 32x1x1 (cuda:0)]\n                (1): Parameter containing: [torch.float32 of size 32x1x1 (cuda:0)]\n                (2): Parameter containing: [torch.float32 of size 32x1x1 (cuda:0)]\n                (3): Parameter containing: [torch.float32 of size 32x1x1 (cuda:0)]\n                (4): Parameter containing: [torch.float32 of size 32x1x1 (cuda:0)]\n                (5): Parameter containing: [torch.float32 of size 32x1x1 (cuda:0)]\n                (6): Parameter containing: [torch.float32 of size 32x1x1 (cuda:0)]\n                (7): Parameter containing: [torch.float32 of size 32x1x1 (cuda:0)]\n            )\n            (trainable_scale_sc): ParameterList(\n                (0): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (1): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (2): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (3): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (4): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (5): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (6): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (7): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n            )\n          )\n          (ofaconv2): OFAGConv(\n            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn_silu): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (trainable_scale_cc): ParameterList(\n                (0): Parameter containing: [torch.float32 of size 32x1x1 (cuda:0)]\n                (1): Parameter containing: [torch.float32 of size 32x1x1 (cuda:0)]\n                (2): Parameter containing: [torch.float32 of size 32x1x1 (cuda:0)]\n                (3): Parameter containing: [torch.float32 of size 32x1x1 (cuda:0)]\n                (4): Parameter containing: [torch.float32 of size 32x1x1 (cuda:0)]\n                (5): Parameter containing: [torch.float32 of size 32x1x1 (cuda:0)]\n                (6): Parameter containing: [torch.float32 of size 32x1x1 (cuda:0)]\n                (7): Parameter containing: [torch.float32 of size 32x1x1 (cuda:0)]\n            )\n            (trainable_scale_sc): ParameterList(\n                (0): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (1): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (2): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (3): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (4): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (5): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (6): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (7): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n            )\n          )\n          (relu): ReLU(inplace=True)\n        )\n      )\n      (layer4): Sequential(\n        (0): OFABasicBlock(\n          (ofaconv1): OFAGConv(\n            (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n            (bn_silu): Sequential(\n              (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (1): ReLU(inplace=True)\n            )\n            (trainable_scale_cc): ParameterList(\n                (0): Parameter containing: [torch.float32 of size 32x1x1 (cuda:0)]\n                (1): Parameter containing: [torch.float32 of size 32x1x1 (cuda:0)]\n                (2): Parameter containing: [torch.float32 of size 32x1x1 (cuda:0)]\n                (3): Parameter containing: [torch.float32 of size 32x1x1 (cuda:0)]\n                (4): Parameter containing: [torch.float32 of size 32x1x1 (cuda:0)]\n                (5): Parameter containing: [torch.float32 of size 32x1x1 (cuda:0)]\n                (6): Parameter containing: [torch.float32 of size 32x1x1 (cuda:0)]\n                (7): Parameter containing: [torch.float32 of size 32x1x1 (cuda:0)]\n            )\n            (trainable_scale_sc): ParameterList(\n                (0): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (1): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (2): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (3): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (4): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (5): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (6): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (7): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n            )\n          )\n          (ofaconv2): OFAGConv(\n            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn_silu): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (trainable_scale_cc): ParameterList(\n                (0): Parameter containing: [torch.float32 of size 64x1x1 (cuda:0)]\n                (1): Parameter containing: [torch.float32 of size 64x1x1 (cuda:0)]\n                (2): Parameter containing: [torch.float32 of size 64x1x1 (cuda:0)]\n                (3): Parameter containing: [torch.float32 of size 64x1x1 (cuda:0)]\n                (4): Parameter containing: [torch.float32 of size 64x1x1 (cuda:0)]\n                (5): Parameter containing: [torch.float32 of size 64x1x1 (cuda:0)]\n                (6): Parameter containing: [torch.float32 of size 64x1x1 (cuda:0)]\n                (7): Parameter containing: [torch.float32 of size 64x1x1 (cuda:0)]\n            )\n            (trainable_scale_sc): ParameterList(\n                (0): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (1): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (2): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (3): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (4): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (5): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (6): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (7): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n            )\n          )\n          (downsample): Sequential(\n            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n          (relu): ReLU(inplace=True)\n        )\n        (1): OFABasicBlock(\n          (ofaconv1): OFAGConv(\n            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn_silu): Sequential(\n              (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (1): ReLU(inplace=True)\n            )\n            (trainable_scale_cc): ParameterList(\n                (0): Parameter containing: [torch.float32 of size 64x1x1 (cuda:0)]\n                (1): Parameter containing: [torch.float32 of size 64x1x1 (cuda:0)]\n                (2): Parameter containing: [torch.float32 of size 64x1x1 (cuda:0)]\n                (3): Parameter containing: [torch.float32 of size 64x1x1 (cuda:0)]\n                (4): Parameter containing: [torch.float32 of size 64x1x1 (cuda:0)]\n                (5): Parameter containing: [torch.float32 of size 64x1x1 (cuda:0)]\n                (6): Parameter containing: [torch.float32 of size 64x1x1 (cuda:0)]\n                (7): Parameter containing: [torch.float32 of size 64x1x1 (cuda:0)]\n            )\n            (trainable_scale_sc): ParameterList(\n                (0): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (1): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (2): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (3): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (4): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (5): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (6): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (7): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n            )\n          )\n          (ofaconv2): OFAGConv(\n            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn_silu): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (trainable_scale_cc): ParameterList(\n                (0): Parameter containing: [torch.float32 of size 64x1x1 (cuda:0)]\n                (1): Parameter containing: [torch.float32 of size 64x1x1 (cuda:0)]\n                (2): Parameter containing: [torch.float32 of size 64x1x1 (cuda:0)]\n                (3): Parameter containing: [torch.float32 of size 64x1x1 (cuda:0)]\n                (4): Parameter containing: [torch.float32 of size 64x1x1 (cuda:0)]\n                (5): Parameter containing: [torch.float32 of size 64x1x1 (cuda:0)]\n                (6): Parameter containing: [torch.float32 of size 64x1x1 (cuda:0)]\n                (7): Parameter containing: [torch.float32 of size 64x1x1 (cuda:0)]\n            )\n            (trainable_scale_sc): ParameterList(\n                (0): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (1): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (2): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (3): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (4): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (5): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (6): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (7): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n            )\n          )\n          (relu): ReLU(inplace=True)\n        )\n      )\n    )\n    (decoder): UnetDecoder(\n      (center): Identity()\n      (blocks): ModuleList(\n        (0): UnetOFADecoderBlock(\n          (conv1): OFAGConv(\n            (conv): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn_silu): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (trainable_scale_cc): ParameterList(\n                (0): Parameter containing: [torch.float32 of size 96x1x1 (cuda:0)]\n                (1): Parameter containing: [torch.float32 of size 96x1x1 (cuda:0)]\n                (2): Parameter containing: [torch.float32 of size 96x1x1 (cuda:0)]\n                (3): Parameter containing: [torch.float32 of size 96x1x1 (cuda:0)]\n                (4): Parameter containing: [torch.float32 of size 96x1x1 (cuda:0)]\n                (5): Parameter containing: [torch.float32 of size 96x1x1 (cuda:0)]\n                (6): Parameter containing: [torch.float32 of size 96x1x1 (cuda:0)]\n                (7): Parameter containing: [torch.float32 of size 96x1x1 (cuda:0)]\n            )\n            (trainable_scale_sc): ParameterList(\n                (0): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (1): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (2): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (3): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (4): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (5): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (6): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (7): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n            )\n          )\n          (attention1): Attention(\n            (attention): Identity()\n          )\n          (conv2): OFAGConv(\n            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn_silu): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (trainable_scale_cc): ParameterList(\n                (0): Parameter containing: [torch.float32 of size 32x1x1 (cuda:0)]\n                (1): Parameter containing: [torch.float32 of size 32x1x1 (cuda:0)]\n                (2): Parameter containing: [torch.float32 of size 32x1x1 (cuda:0)]\n                (3): Parameter containing: [torch.float32 of size 32x1x1 (cuda:0)]\n                (4): Parameter containing: [torch.float32 of size 32x1x1 (cuda:0)]\n                (5): Parameter containing: [torch.float32 of size 32x1x1 (cuda:0)]\n                (6): Parameter containing: [torch.float32 of size 32x1x1 (cuda:0)]\n                (7): Parameter containing: [torch.float32 of size 32x1x1 (cuda:0)]\n            )\n            (trainable_scale_sc): ParameterList(\n                (0): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (1): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (2): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (3): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (4): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (5): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (6): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (7): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n            )\n          )\n          (attention2): Attention(\n            (attention): Identity()\n          )\n          (haf): HAF(\n            (sa): DCA(\n              (conv_large): GlobalBranch(\n                (activaton): Sigmoid()\n              )\n              (conv_small): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            )\n            (conv_out): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          )\n        )\n        (1): UnetOFADecoderBlock(\n          (conv1): OFAGConv(\n            (conv): Conv2d(48, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn_silu): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (trainable_scale_cc): ParameterList(\n                (0): Parameter containing: [torch.float32 of size 48x1x1 (cuda:0)]\n                (1): Parameter containing: [torch.float32 of size 48x1x1 (cuda:0)]\n                (2): Parameter containing: [torch.float32 of size 48x1x1 (cuda:0)]\n                (3): Parameter containing: [torch.float32 of size 48x1x1 (cuda:0)]\n                (4): Parameter containing: [torch.float32 of size 48x1x1 (cuda:0)]\n                (5): Parameter containing: [torch.float32 of size 48x1x1 (cuda:0)]\n                (6): Parameter containing: [torch.float32 of size 48x1x1 (cuda:0)]\n                (7): Parameter containing: [torch.float32 of size 48x1x1 (cuda:0)]\n            )\n            (trainable_scale_sc): ParameterList(\n                (0): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (1): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (2): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (3): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (4): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (5): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (6): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (7): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n            )\n          )\n          (attention1): Attention(\n            (attention): Identity()\n          )\n          (conv2): OFAGConv(\n            (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn_silu): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (trainable_scale_cc): ParameterList(\n                (0): Parameter containing: [torch.float32 of size 16x1x1 (cuda:0)]\n                (1): Parameter containing: [torch.float32 of size 16x1x1 (cuda:0)]\n                (2): Parameter containing: [torch.float32 of size 16x1x1 (cuda:0)]\n                (3): Parameter containing: [torch.float32 of size 16x1x1 (cuda:0)]\n                (4): Parameter containing: [torch.float32 of size 16x1x1 (cuda:0)]\n                (5): Parameter containing: [torch.float32 of size 16x1x1 (cuda:0)]\n                (6): Parameter containing: [torch.float32 of size 16x1x1 (cuda:0)]\n                (7): Parameter containing: [torch.float32 of size 16x1x1 (cuda:0)]\n            )\n            (trainable_scale_sc): ParameterList(\n                (0): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (1): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (2): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (3): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (4): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (5): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (6): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n                (7): Parameter containing: [torch.float32 of size 1x3x3 (cuda:0)]\n            )\n          )\n          (attention2): Attention(\n            (attention): Identity()\n          )\n          (haf): HAF(\n            (sa): DCA(\n              (conv_large): GlobalBranch(\n                (activaton): Sigmoid()\n              )\n              (conv_small): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            )\n            (conv_out): Conv2d(128, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          )\n        )\n        (2): UnetDecoderBlock(\n          (conv1): Conv2dReLU(\n            (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU(inplace=True)\n          )\n          (attention1): Attention(\n            (attention): Identity()\n          )\n          (conv2): Conv2dReLU(\n            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU(inplace=True)\n          )\n          (attention2): Attention(\n            (attention): Identity()\n          )\n          (haf): HAF(\n            (sa): DCA(\n              (conv_large): GlobalBranch(\n                (activaton): Sigmoid()\n              )\n              (conv_small): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            )\n            (conv_out): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          )\n        )\n        (3): UnetDecoderBlock(\n          (conv1): Conv2dReLU(\n            (0): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU(inplace=True)\n          )\n          (attention1): Attention(\n            (attention): Identity()\n          )\n          (conv2): Conv2dReLU(\n            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU(inplace=True)\n          )\n          (attention2): Attention(\n            (attention): Identity()\n          )\n          (haf): HAF(\n            (sa): DCA(\n              (conv_large): GlobalBranch(\n                (activaton): Sigmoid()\n              )\n              (conv_small): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            )\n            (conv_out): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          )\n        )\n        (4): UnetDecoderBlock(\n          (conv1): Conv2dReLU(\n            (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU(inplace=True)\n          )\n          (attention1): Attention(\n            (attention): Identity()\n          )\n          (conv2): Conv2dReLU(\n            (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU(inplace=True)\n          )\n          (attention2): Attention(\n            (attention): Identity()\n          )\n          (haf): HAF(\n            (sa): DCA(\n              (conv_large): GlobalBranch(\n                (activaton): Sigmoid()\n              )\n              (conv_small): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            )\n            (conv_out): Conv2d(16, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          )\n        )\n      )\n    )\n    (segmentation_head): SegmentationHead(\n      (0): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): Identity()\n      (2): Identity()\n    )\n  )\n)\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"'\\n--OFA-UNet\\n'"},"metadata":{}}],"execution_count":5},{"cell_type":"markdown","source":"# train","metadata":{"papermill":{"duration":0.005835,"end_time":"2025-11-04T02:49:19.520016","exception":false,"start_time":"2025-11-04T02:49:19.514181","status":"completed"},"tags":[]}},{"cell_type":"code","source":"Resume_Train = None\nimport segmentation_models_pytorch as smp\n\nn_eps = 50 # Tổng số epoch muốn train\nlr = 1e-3 # Sẽ được dùng bởi optimizer\nscheduler_step_size = 20 # Sẽ được dùng bởi scheduler\nscheduler_gamma = 0.2 # Sẽ được dùng bởi scheduler\nnum_classes = 4 # Số lượng lớp của bài toán\n\ncriterion_dice = smp.losses.DiceLoss(\n    mode='multiclass', \n    from_logits=True\n).to(device)\ncriterion_ce = nn.CrossEntropyLoss(label_smoothing=0.1).to(device)\n# criterion_dice = DiceLoss(num_classes=num_classes).to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=lr) # Giả sử đã định nghĩa ở ngoài\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=scheduler_step_size, gamma=scheduler_gamma) # Giả sử đã định nghĩa\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nclass AverageMeter: # Giữ nguyên AverageMeter cho loss\n    def __init__(self): self.reset()\n    def reset(self): self.val, self.avg, self.sum, self.count = 0, 0, 0, 0\n    def update(self, val, n=1): self.val = val; self.sum += val * n; self.count += n; self.avg = self.sum / self.count\n\n\ndef evaluate(model, dataloader, criterion_ce, criterion_dice, device, num_classes):\n    # [QUAN TRỌNG] Chuyển model sang chế độ đánh giá\n    # Lệnh này sẽ set self.training = False trong model\n    # => Model sẽ TẮT nhánh aux và chỉ trả về 1 giá trị (main output)\n    model.eval() \n    \n    test_loss_meter = AverageMeter()\n    eval_accuracy_metric = Accuracy(task=\"multiclass\", num_classes=num_classes, average='micro').to(device)\n    eval_iou_metric = JaccardIndex(task=\"multiclass\", num_classes=num_classes, average='macro').to(device)\n\n    with torch.no_grad():\n        for x, y in tqdm(dataloader, desc=\"Evaluating\"):\n            x, y = x.to(device), y.to(device)\n            \n            # Vì đã gọi model.eval(), model chỉ trả về 1 tensor\n            y_hat = model(x) \n            loss_d = criterion_dice(y_hat, y)\n            loss_c = criterion_ce(y_hat, y)\n            loss = loss_d + loss_c\n            test_loss_meter.update(loss.item(), n=y.size(0))\n\n            preds = torch.argmax(y_hat, dim=1)\n            eval_accuracy_metric.update(preds, y)\n            eval_iou_metric.update(preds, y)\n\n    return test_loss_meter.avg, eval_accuracy_metric.compute().item(), eval_iou_metric.compute().item()\n\n\n# --- Thêm các danh sách để lưu lịch sử metrics ---\ntrain_acc_history = []\ntrain_iou_history = []\ntest_acc_history = []\ntest_iou_history = []\n# ----------------------------------------------\n\nstart_epoch = 1\nbest_test_mean_iou = 0.0\nbest_epoch_val = 0\n\n# print(\"\\n\" + \"=\"*50)\n# print(\"KIỂM TRA CẤU HÌNH DEPLOY (INFERENCE)\")\n# model.eval() # Chuyển sang eval: Logic forward sẽ bỏ qua nhánh aux\n\n# # 1. Tổng tham số đang nạp trong RAM (Bao gồm cả Aux chưa cắt bỏ)\n# total_params = sum(p.numel() for p in model.parameters())\n\n# # 2. Tính riêng tham số của nhánh Aux (Dựa vào tên biến self.aux_head trong UnetDecoder)\n# # Lưu ý: Cần truy cập đúng đường dẫn: model -> decoder -> aux_head\n# try:\n#     # Nếu model bọc trong DataParallel, cần gọi model.module\n#     if isinstance(model, nn.DataParallel) or isinstance(model, nn.parallel.DistributedDataParallel):\n#         aux_head_params = sum(p.numel() for p in model.module.decoder.aux_head.parameters())\n#     else:\n#         aux_head_params = sum(p.numel() for p in model.decoder.aux_head.parameters())\n# except AttributeError:\n#     aux_head_params = 0\n#     print(\"Warning: Không tìm thấy module 'aux_head' để đếm riêng.\")\n\n# # 3. Tham số thực tế (Effective Params) cho Inference\n# inference_params = total_params - aux_head_params\n\n# print(f\"1. Tổng số tham số trong bộ nhớ (Training build): {total_params:,}\")\n# print(f\"2. Số tham số của nhánh Aux (Chỉ dùng khi Train): {aux_head_params:,}\")\n# print(f\"3. -> Số tham số thực tế dùng khi Deploy (Main only): {inference_params:,}\")\n# print(\"=\"*50 + \"\\n\")\n# # ==============================================================================\n\nprint(\"Bắt đầu training với Loss = CE_Main + 0.4 * CE_Aux\")\n\nfor ep in range(start_epoch, n_eps + 1):\n    \n    # 1. TRAIN MODE\n    model.train() \n    \n    train_loss_meter = AverageMeter() \n    loss_main_meter = AverageMeter()\n    loss_aux_meter = AverageMeter()\n\n    epoch_global_accuracy_metric = Accuracy(task=\"multiclass\", num_classes=num_classes, average='micro').to(device)\n    epoch_mean_iou_metric = JaccardIndex(task=\"multiclass\", num_classes=num_classes, average='macro').to(device)\n\n    with tqdm(trainloader, desc=f\"Training Epoch {ep}/{n_eps}\", unit=\"batch\") as tepoch:\n        for x, y in tepoch:\n            optimizer.zero_grad()\n            x, y = x.to(device), y.to(device)\n            \n            # --- Forward Pass ---\n            y_hat, y_aux = model(x) \n            \n            # --- Tính Loss ---\n            loss_dice = criterion_dice(y_hat, y)\n            \n            # Soft CE Loss (PyTorch native)\n            loss_ce = criterion_ce(y_hat, y)\n            \n            loss_principal = loss_dice + loss_ce\n            loss_aux = criterion_dice(y_aux, y)\n            loss = loss_principal + 0.25 * loss_aux\n            \n            # --- Backward Pass ---\n            loss.backward()\n            optimizer.step()\n\n            # --- Logging ---\n            train_loss_meter.update(loss.item(), n=y.size(0))\n            loss_main_meter.update(loss_principal.item(), n=y.size(0))\n            loss_aux_meter.update(loss_aux.item(), n=y.size(0))\n\n            # Metric Calculation (Chỉ dùng main output)\n            preds = torch.argmax(y_hat, dim=1) \n            epoch_global_accuracy_metric.update(preds, y)\n            epoch_mean_iou_metric.update(preds, y)\n\n            tepoch.set_postfix(\n                total=train_loss_meter.avg, \n                main=loss_main_meter.avg,\n                aux=loss_aux_meter.avg,\n                mIoU=epoch_mean_iou_metric.compute().item()\n            )\n\n    # --- LẤY METRICS TRAIN (Đồng bộ tên biến) ---\n    train_loss = train_loss_meter.avg\n    train_acc = epoch_global_accuracy_metric.compute().item()\n    train_iou = epoch_mean_iou_metric.compute().item()\n    # print(self.training)\n\n    # --- EVALUATION ---\n    # Hàm evaluate trả về 3 giá trị, gán vào 3 biến chuẩn\n    test_loss, test_acc, test_iou = evaluate(model, testloader, criterion_ce, criterion_dice, device, num_classes)\n    # print(self.training)\n\n    # --- LƯU HISTORY ---\n    train_acc_history.append(train_acc)\n    train_iou_history.append(train_iou)\n    test_acc_history.append(test_acc)\n    test_iou_history.append(test_iou)\n\n    # --- IN KẾT QUẢ ---\n    print(f\"\\n--- Epoch {ep}/{n_eps} ---\")\n    print(f\"LR: {scheduler.get_last_lr()[0]:.6f}\")\n    print(f\"Train: Loss Total={train_loss:.4f} (Main={loss_main_meter.avg:.4f}, Aux={loss_aux_meter.avg:.4f})\")\n    print(f\"Train Metrics: Acc={train_acc:.4f}, mIoU={train_iou:.4f}\")\n    print(f\"Test Metrics:  Loss={test_loss:.4f}, Acc={test_acc:.4f}, mIoU={test_iou:.4f}\")\n    \n    scheduler.step()\n\n    # --- LƯU CHECKPOINT ---\n    # Sửa lỗi: Dùng biến test_acc và test_iou vừa định nghĩa ở trên\n    epoch_checkpoint_path = f\"epoch_{ep}_Acc_{test_acc:.4f}_mIoU_{test_iou:.4f}.pth\"\n    \n    torch.save({\n        'epoch': ep,\n        'model_state_dict': model.state_dict(),\n        'optimizer_state_dict': optimizer.state_dict(),\n        'scheduler_state_dict': scheduler.state_dict(),\n        'current_test_global_accuracy': test_acc, # Map đúng biến test_acc\n        'current_test_mean_iou': test_iou,        # Map đúng biến test_iou\n        'train_loss': train_loss,                 # Map đúng biến train_loss\n        'test_loss': test_loss,\n        'best_test_mean_iou': best_test_mean_iou,\n        'best_epoch': best_epoch_val,\n    }, epoch_checkpoint_path)\n    \n    print(f\"Đã lưu checkpoint: {epoch_checkpoint_path}\")\n\n    # --- SO SÁNH BEST MODEL ---\n    if test_iou > best_test_mean_iou:\n        best_test_mean_iou = test_iou\n        best_epoch_val = ep\n        print(f\"--> Đạt Best Mean IoU mới: {best_test_mean_iou:.4f} tại epoch {best_epoch_val}\")\n    \n    print(\"-\" * 50)\n\nprint(f\"\\nHoàn tất training sau {n_eps} epochs.\")\nprint(f\"Model tốt nhất đạt Test Mean IoU: {best_test_mean_iou:.4f} tại epoch {best_epoch_val}\")\n\nplotted_epochs_range = list(range(start_epoch, ep + 1 if 'ep' in locals() else start_epoch))\n\n\nif len(plotted_epochs_range) > 0 and len(train_acc_history) > 0: # Kiểm tra có dữ liệu\n    plt.figure(figsize=(12, 5))\n\n    plt.subplot(1, 2, 1)\n    plt.plot(plotted_epochs_range, train_acc_history, label='Train Accuracy')\n    plt.plot(plotted_epochs_range, test_acc_history, label='Validation Accuracy')\n    plt.xlabel('Epoch')\n    plt.ylabel('Accuracy')\n    plt.title('Training and Validation Accuracy')\n    plt.legend()\n    plt.grid(True)\n\n    plt.subplot(1, 2, 2)\n    plt.plot(plotted_epochs_range, train_iou_history, label='Train IoU', color='green')\n    plt.plot(plotted_epochs_range, test_iou_history, label='Validation IoU', color='red')\n    plt.xlabel('Epoch')\n    plt.ylabel('IoU')\n    plt.title('Training and Validation IoU')\n    plt.legend()\n    plt.grid(True)\n\n    plt.tight_layout()\n    plt.savefig('training_progress_plot.png')\n    plt.show()\nelse:\n    print(\"Không có dữ liệu epoch để vẽ đồ thị (hoặc chưa chạy epoch nào trong phiên này).\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T14:41:27.648894Z","iopub.execute_input":"2026-02-02T14:41:27.649164Z","execution_failed":"2026-02-02T14:44:43.507Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Bắt đầu training với Loss = CE_Main + 0.4 * CE_Aux\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 1/50:  16%|█▋        | 432/2625 [03:09<16:38,  2.20batch/s, aux=0.261, mIoU=0.653, main=0.921, total=0.986]","output_type":"stream"}],"execution_count":null},{"cell_type":"markdown","source":"# show","metadata":{"papermill":{"duration":3.603442,"end_time":"2025-11-04T06:11:18.497152","exception":false,"start_time":"2025-11-04T06:11:14.893710","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import torch\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport random\nfrom matplotlib.colors import ListedColormap # Đảm bảo đã import\nimport glob\nimport os\n\n# --- Hàm để hiển thị ảnh, ground truth mask và predicted mask (ĐÃ CẬP NHẬT) ---\ndef visualize_segmentation(images_tensor, true_masks_tensor, pred_masks_tensor, colormap_definition, num_samples=36, num_cols=6):\n    \"\"\"\n    Hiển thị các mẫu ảnh, ground truth mask và predicted mask.\n    Args:\n        images_tensor (Tensor): Batch ảnh (N, C, H, W) đã được chuẩn hóa từ DataLoader.\n                                Giá trị pixel được giả định trong khoảng [0, 1].\n        true_masks_tensor (Tensor): Batch ground truth masks (N, H, W) chứa chỉ số lớp.\n        pred_masks_tensor (Tensor): Batch predicted masks (N, H, W) chứa chỉ số lớp.\n        colormap_definition (list): List các màu [[R,G,B], ...] cho các lớp.\n        num_samples (int): Số lượng mẫu cần hiển thị.\n        num_cols (int): Số cột trong lưới hiển thị.\n    \"\"\"\n    images_np_list = []\n    # images_tensor là (N,C,H,W) tensor với giá trị pixel trong khoảng [0,1]\n    for img_t in images_tensor:\n        img_chw_01 = img_t.cpu().numpy() # (C,H,W), giá trị trong [0,1]\n        img_hwc_uint8 = (img_chw_01.transpose(1, 2, 0) * 255).astype(np.uint8)\n        images_np_list.append(img_hwc_uint8)\n\n    true_masks_np = true_masks_tensor.cpu().numpy()\n    pred_masks_np = pred_masks_tensor.cpu().numpy()\n\n    # Điều chỉnh số lượng mẫu thực tế nếu không đủ\n    actual_num_samples = min(num_samples, len(images_np_list))\n    if actual_num_samples == 0:\n        print(\"Không có mẫu nào để hiển thị.\")\n        return\n        \n    total_items = actual_num_samples * 3\n    num_rows = (total_items + num_cols - 1) // num_cols # Làm tròn lên\n\n    fig_height = num_rows * 3 # Điều chỉnh chiều cao dựa trên số hàng\n    fig_width = num_cols * 3\n\n    plt.figure(figsize=(fig_width, fig_height))\n\n    custom_cmap = ListedColormap(np.array(colormap_definition) / 255.0)\n    num_classes = len(colormap_definition)\n\n    for i in range(actual_num_samples):\n        plot_idx_base = i * 3\n\n        # Ảnh gốc\n        plt.subplot(num_rows, num_cols, plot_idx_base + 1)\n        plt.imshow(images_np_list[i])\n        plt.title(f\"Image {i+1}\")\n        plt.axis('off')\n\n        # Ground Truth Mask\n        plt.subplot(num_rows, num_cols, plot_idx_base + 2)\n        plt.imshow(true_masks_np[i], cmap=custom_cmap, vmin=0, vmax=num_classes-1)\n        plt.title(f\"GT Mask {i+1}\")\n        plt.axis('off')\n\n        # Predicted Mask\n        plt.subplot(num_rows, num_cols, plot_idx_base + 3)\n        plt.imshow(pred_masks_np[i], cmap=custom_cmap, vmin=0, vmax=num_classes-1)\n        plt.title(f\"Pred Mask {i+1}\")\n        plt.axis('off')\n\n    plt.tight_layout()\n    plt.show()\n\n\ntry:\n    model_files = glob.glob(\"epoch_*_GlobalAccuracy_*_MeanIoU_*.pth\")\n    if not model_files:\n        raise FileNotFoundError(\"Không tìm thấy file.\")\n\n\n    model_files.sort(key=lambda f:\n                     (lambda parts:\n                          # Định dạng chính: epoch_XX_GlobalAccuracy_YY.YYYY_MeanIoU_ZZ.ZZZZ\n                          (float(parts[5]) if len(parts) > 5 and parts[4] == 'MeanIoU' else -1.0, # Ưu tiên MeanIoU\n                           int(parts[1]) if len(parts) > 1 else -1) # Sau đó là epoch\n                           # if len(parts) > 0 and parts[0] == 'epoch'\n                           # Định dạng fallback: best_model_epoch_XX_acc_YY.YYYY (Sắp xếp theo acc nếu không có MeanIoU)\n                           # else (float(parts[5]) if len(parts) > 5 and parts[4] == 'acc' else -1.0,\n                           #       int(parts[3]) if len(parts) > 3 else -1)\n                           #       if len(parts) > 1 and parts[0] == 'best' and parts[1] == 'model'\n                           #       # Mặc định cho các tên file không khớp\n                           #       else (-1.0, -1)\n                     )(os.path.basename(f).replace('.pth', '').split('_')), # Phân tích tên file\n                     reverse=True) # Sắp xếp giảm dần để lấy giá trị cao nhất trước\n\n    best_path = model_files[0]\n    print(f\"Đang tải trọng số từ: {best_path}\")\n\n    checkpoint = torch.load(best_path, map_location=device)\n    model.load_state_dict(checkpoint['model_state_dict'])\n\n    model.to(device)\n    model.eval() # Đặt model ở chế độ đánh giá\n    print(\"Đã tải trọng số thành công!\")\n\nexcept FileNotFoundError as e:\n    print(e)\nexcept Exception as e:\n    print(f\"Lỗi khi tải model: {e}\")\n\n\n\nif 'model' in locals() and hasattr(model, 'load_state_dict') and 'testloader' in globals() and 'COLORMAP' in globals():\n    try:\n        all_images_tensors_list = []\n        all_true_masks_tensors_list = []\n\n        for batch_idx, (x_test_batch, y_test_batch) in enumerate(testloader):\n            all_images_tensors_list.append(x_test_batch)\n            all_true_masks_tensors_list.append(y_test_batch)\n\n\n        if not all_images_tensors_list:\n            print(\"Không có dữ liệu nào được lấy từ testloader.\")\n        else:\n            # Ghép toàn bộ dữ liệu đã lấy từ testloader\n            all_images_combined = torch.cat(all_images_tensors_list, dim=0)\n            all_true_masks_combined = torch.cat(all_true_masks_tensors_list, dim=0)\n\n            num_total_available = all_images_combined.size(0)\n\n            num_to_visualize = min(36, num_total_available)\n\n            if num_to_visualize > 0:\n                if num_to_visualize == 1:\n                    sampled_indices = [0]\n                else:\n                    step = num_total_available / num_to_visualize\n                    sampled_indices = [int(i * step) for i in range(num_to_visualize)]\n                    sampled_indices = [min(idx, num_total_available - 1) for idx in sampled_indices]\n\n\n                print(f\"Đã lấy TOÀN BỘ dữ liệu từ testloader ({num_total_available} mẫu).\")\n                print(f\"Tuy nhiên, chỉ hiển thị {num_to_visualize} mẫu cách đều với các chỉ mục: {sampled_indices}\")\n\n                # Lấy các mẫu đã chọn để hiển thị\n                sampled_images_tensor = all_images_combined[sampled_indices]\n                sampled_masks_tensor = all_true_masks_combined[sampled_indices]\n\n                sampled_images_tensor_dev = sampled_images_tensor.to(device).float()\n\n                pred_masks_list = []\n                with torch.no_grad():\n                    outputs = model(sampled_images_tensor_dev)\n                    predictions = torch.softmax(outputs, dim=1).argmax(dim=1)\n                    pred_masks_list.extend(predictions.cpu())\n\n                final_pred_masks_tensor = torch.stack(pred_masks_list)\n\n                visualize_segmentation(\n                    sampled_images_tensor,        # Tensor ảnh gốc (đã chuẩn hóa)\n                    sampled_masks_tensor,         # Tensor mặt nạ ground truth\n                    final_pred_masks_tensor,      # Tensor mặt nạ dự đoán\n                    COLORMAP,                     # Định nghĩa colormap\n                    num_samples=num_to_visualize\n                )\n            else:\n                print(f\"Đã lấy TOÀN BỘ dữ liệu từ testloader ({num_total_available} mẫu), nhưng không có mẫu nào được chọn để hiển thị (num_to_visualize là 0).\")\n\n    except NameError as e:\n        print(f\"Lỗi NameError: {e}. Đảm bảo các biến cần thiết (như 'device', 'visualize_segmentation') đã được định nghĩa.\")\n    except Exception as e:\n        print(f\"Có lỗi xảy ra trong quá trình dự đoán hoặc hiển thị: {e}\")\nelse:\n    print(\"Mô hình chưa được tải hoặc 'testloader'/'COLORMAP' chưa được định nghĩa. Bỏ qua phần hiển thị.\")\n","metadata":{"papermill":{"duration":69.350352,"end_time":"2025-11-04T06:12:31.488164","exception":false,"start_time":"2025-11-04T06:11:22.137812","status":"completed"},"tags":[],"trusted":true,"execution":{"execution_failed":"2026-02-02T14:44:43.508Z"}},"outputs":[],"execution_count":null}]}